# 计算机基础

## 进程

### 进程间通信方式

每个进程各自有不同的用户地址空间，任何一个进程的全局变量在另一个进程中都看不到，所以进程之间要交换数据必须通过内核，在内核中开辟一块缓冲区，进程1把数据从用户空间拷到内核缓冲区，进程2再从内核缓冲区把数据读走，内核提供的这种机制称为进程间通信（IPC，InterProcess Communication）

#### 1. 管道/匿名管道(pipe)

管道是半双工的，数据只能向一个方向流动；需要双方通信时，需要建立起两个管道。
只能用于父子进程或者兄弟进程之间(具有亲缘关系的进程);
单独构成一种独立的文件系统：管道对于管道两端的进程而言，就是一个文件，但它不是普通的文件，它不属于某种文件系统，而是自立门户，单独构成一种文件系统，并且只存在与内存中。
数据的读出和写入：一个进程向管道中写的内容被管道另一端的进程读出。写入的内容每次都添加在管道缓冲区的末尾，并且每次都是从缓冲区的头部读出数据。

#### 2. 有名管道(FIFO)

匿名管道，由于没有名字，只能用于亲缘关系的进程间通信。为了克服这个缺点，提出了有名管道(FIFO)。
有名管道不同于匿名管道之处在于它提供了一个路径名与之关联，以有名管道的文件形式存在于文件系统中，这样，即使与有名管道的创建进程不存在亲缘关系的进程，只要可以访问该路径，就能够彼此通过有名管道相互通信，因此，通过有名管道不相关的进程也能交换数据。值的注意的是，有名管道严格遵循先进先出(first in first out),对匿名管道及有名管道的读总是从开始处返回数据，对它们的写则把数据添加到末尾。它们不支持诸如lseek()等文件定位操作。有名管道的名字存在于文件系统中，内容存放在内存中。

#### 3. 信号(Signal)

信号是Linux系统中用于进程间互相通信或者操作的一种机制，信号可以在任何时候发给某一进程，而无需知道该进程的状态。
如果该进程当前并未处于执行状态，则该信号就有内核保存起来，知道该进程回复执行并传递给它为止。
如果一个信号被进程设置为阻塞，则该信号的传递被延迟，直到其阻塞被取消是才被传递给进程。

#### 4. 消息(Message)队列

消息队列是存放在内核中的消息链表，每个消息队列由消息队列标识符表示。
与管道（无名管道：只存在于内存中的文件；命名管道：存在于实际的磁盘介质或者文件系统）不同的是消息队列存放在内核中，只有在内核重启(即，操作系统重启)或者显示地删除一个消息队列时，该消息队列才会被真正的删除。
另外与管道不同的是，消息队列在某个进程往一个队列写入消息之前，并不需要另外某个进程在该队列上等待消息的到达。

#### 5. 共享内存(share memory)

使得多个进程可以可以直接读写同一块内存空间，是最快的可用IPC形式。是针对其他通信机制运行效率较低而设计的。
为了在多个进程间交换信息，内核专门留出了一块内存区，可以由需要访问的进程将其映射到自己的私有地址空间。进程就可以直接读写这一块内存而不需要进行数据的拷贝，从而大大提高效率。
由于多个进程共享一段内存，因此需要依靠某种同步机制（如信号量）来达到进程间的同步及互斥。

#### 6. 信号量(semaphore)

信号量是一个计数器，用于多进程对共享数据的访问，信号量的意图在于进程间同步。
为了获得共享资源，进程需要执行下列操作：
（1）创建一个信号量：这要求调用者指定初始值，对于二值信号量来说，它通常是1，也可是0。
（2）等待一个信号量：该操作会测试这个信号量的值，如果小于0，就阻塞。也称为P操作。
（3）挂出一个信号量：该操作将信号量的值加1，也称为V操作。

为了正确地实现信号量，信号量值的测试及减1操作应当是原子操作。为此，信号量通常是在内核中实现的。Linux环境中，有三种类型：Posix（可移植性操作系统接口）有名信号量（使用Posix IPC名字标识）、Posix基于内存的信号量（存放在共享内存区中）、System V信号量（在内核中维护）。这三种信号量都可用于进程间或线程间的同步。

#### 7. 套接字(socket)

套接字是一种通信机制，凭借这种机制，客户/服务器（即要进行通信的进程）系统的开发工作既可以在本地单机上进行，也可以跨网络进行。也就是说它可以让不在同一台计算机但通过网络连接计算机上的进程进行通信。

## 互联网协议

### 五层模型

应用层 传输层 网络层 链接层 实体层

### 实体层

实体层就是物理手段，如光纤等。

### 链接层

通过以太网协议将每个数据包分为两个部分：标头和数据

标头包含一些说明信息，包括发送者，接收者，数据类型等。

那么发送接收者如何确定呢？这个是通过一个叫网卡的硬件，网卡上有每个电脑独一无二的mac地址。以太网规定数据必须是从一块网卡传动到另一块网卡。

有了接收方，如何进行传输呢？以太网采用“广播”的方式。将数据包发送到**本网络**内的**所有计算机**，让每台计算机自己判断自己是不是接收方。

链接层主要**缺点**：如果要接收数据必须使两台电脑在同一个子网络。这是因为广播如果直接用于互联网数据量非常大。

### 网络层

既然如此，我们可以先判断两台电脑是否在同一个子网，如果在同一个子网就采用广播方式，如果不在，就采用路由想不通的子网络发送数据包。于是网络层应运而生。

网络层采用ip协议，依托于ip地址。

IP地址分为两部分，前一部分代表网络，后一部分代表主机。

但是如何划分呢？采用子网掩码的模式，将两部分与运算得到。

子网掩码也可以分为两部分，前一部分全1，后一部分全零。与运算之后也就是将全1部分对应的ip地址提取出来。

子网掩码一般采用“/n”表示，n表示前几位为1。比如192.168.0.1/24 那么网络就是192.168.0.0 网络相同即处于同一个子网下。同时可以得出ip总数就是2的8次方，也就是256。

那么可以得出ip地址主要有两个作用：1.为每台计算机分配一个（同一环境下）独一无二的ip地址。2.确定哪些地址在同一个子网络。

ip数据包中也含有标头，ip数据包直接放在以太网数据包的“数据”部分

### 传输层

包传输到电脑之后，需要一个参数表示这个数据包是提供给哪个程序的。因为同一时刻可能有多个程序在运行。这个参数就是**端口**

Unix把主机+端口叫做“套接字”socket

"传输层"的功能，就是建立"端口到端口"的通信。相比之下，"网络层"的功能是建立"主机到主机"的通信。只要确定主机和端口，我们就能实现程序之间的交流。

现在我们需要加入端口协议，常见的端口协议有两种。UDP TCP

#### UDP

UDP的包头放在IP数据包的数据部分，IP的包头又放在以太网数据包中。

UDP数据包非常简单，标头部分一共只有八个字节，正好放进一个IP数据包。

优点：
简单，容易实现
缺点：
可靠性差，一旦数据发出，无法知道对方是否收到

#### TCP协议

TCP协议就诞生了。这个协议非常复杂，但可以近似认为，**TCP就是有确认机制的UDP协议**，每发出一个数据包都要求确认。如果有一个数据包遗失，就收不到确认，发出方就知道有必要重发这个数据包了。

TCP协议能够确保数据不会遗失。它的缺点是过程复杂、实现困难、消耗较多的资源。
![img](./img/以太网数据包.png)

### 应用层

"应用层"的作用，就是规定应用程序的数据格式。它直接面对用户。它的数据就放在TCP数据包的"数据"部分。

## http

### http 1.0

#### 连接复用

解决方法：

1.header设置keep-alive
2.基于tcp的长连接
3.http long-polling：

Long Polling原理很简单，相比Polling，客户端发起Long Polling，此时如果服务端没有相关数据，会hold住请求，直到服务端有相关数据，或者等待一定时间超时才会返回。返回后，客户端又会立即再次发起下一次Long Polling。这种方式也是对拉模式的一个优化，解决了拉模式数据通知不及时，以及减少了大量的无效轮询次数。（所谓的hold住请求指的服务端暂时不回复结果，保存相关请求，不关闭请求连接，等相关数据准备好，写会客户端。）

4.http streaming
5.web socket

#### head of line blocking

pipelineing：HTTP Pipelining其实是把多个HTTP请求放到一个TCP连接中一一发送，而在发送过程中不需要等待服务器对前一个请求的响应；只不过，客户端还是要**按照发送请求的顺序来接收响应**。

### http2

#### HTTP/1.1 存在的问题:

1、TCP 连接数限制

对于同一个域名，浏览器最多只能同时创建 6~8 个 TCP 连接 (不同浏览器不一样)。
为了解决数量限制，出现了 域名分片 技术，其实就是资源分域，将资源放在不同域名下

2、线头阻塞 (Head Of Line Blocking) 问题

每个 TCP 连接同时只能处理一个请求 - 响应，浏览器按 FIFO 原则处理请求，如果上一个响应没返回，后续请求 - 响应都会受阻。

为了解决此问题，出现了 管线化 - pipelining 技术，但是管线化存在诸多问题，比如第一个响应慢还是会阻塞后续响应、服务器为了按序返回相应需要缓存多个响应占用更多资源、浏览器中途断连重试服务器可能得重新处理多个请求、还有必须客户端 - 代理 - 服务器都支持管线化

3、Header 内容多，而且每次请求 Header 不会变化太多，没有相应的压缩传输优化方案

4、为了尽可能减少请求数，需要做合并文件、雪碧图、资源内联等优化工作，但是这无疑造成了单个请求内容变大延迟变高的问题，且内嵌的资源不能有效地使用缓存机制

5、明文传输不安全


#### HTTP2 的优势

同域名下所有通信都在单个连接上完成。
单个连接可以承载任意数量的双向数据流。
数据流以消息的形式发送，而消息又由一个或多个帧组成，多个帧之间可以**乱序**发送，因为根据帧首部的流标识可以重新组装。

1. 二进制分帧层 (Binary Framing Layer)

帧是数据传输的最小单位，以二进制传输代替原本的明文传输，原本的报文消息被划分为更小的数据帧:

HTTP1.x的解析是基于文本。基于文本协议的格式解析存在天然缺陷，文本的表现形式有多样性，要做到健壮性考虑的场景必然很多，二进制则不同，只认0和1的组合。基于这种考虑HTTP2.0的协议解析决定采用二进制格式，实现方便且健壮。

2. 多路复用 (MultiPlexing)

在一个 TCP 连接上，我们可以向对方不断发送帧，每帧的 stream identifier 的标明这一帧属于哪个流，然后在对方接收时，根据 stream identifier 拼接每个流的所有帧组成一整块数据。
把 HTTP/1.1 每个请求都当作一个流，那么多个请求变成多个流，请求响应数据分成多个帧，不同流中的帧交错地发送给对方，这就是 HTTP/2 中的多路复用。

流的概念实现了单连接上多请求 - 响应并行，解决了线头阻塞的问题，减少了 TCP 连接数量和 TCP 连接慢启动造成的问题

所以 http2 对于同一域名**只需要创建一个连接**，而不是像 http/1.1 那样创建 6~8 个连接

3. 服务端推送 (Server Push)
浏览器发送一个请求，服务器主动向浏览器推送与这个请求相关的资源，这样浏览器就不用发起后续请求。

4. Header 压缩 (HPACK)
使用 HPACK 算法来压缩首部内容

5. 应用层的重置连接
对于 HTTP/1 来说，是通过设置 tcp segment 里的 reset flag 来通知对端关闭连接的。这种方式会直接断开连接，下次再发请求就必须重新建立连接。HTTP/2 引入 RST_STREAM 类型的 frame，可以在不断开连接的前提下取消某个 request 的 stream，表现更好。

6. 请求优先级设置
HTTP/2 里的每个 stream 都可以设置依赖 (Dependency) 和权重，可以按依赖树分配优先级，解决了关键请求被阻塞的问题

7. 流量控制
每个 http2 流都拥有自己的公示的流量窗口，它可以限制另一端发送数据。对于每个流来说，两端都必须告诉对方自己还有足够的空间来处理新的数据，而在该窗口被扩大前，另一端只被允许发送这么多数据。

8. HTTP/1 的几种优化可以弃用
合并文件、内联资源、雪碧图、域名分片对于 HTTP/2 来说是不必要的，使用 h2 尽可能将资源细粒化，文件分解地尽可能散，不用担心请求数多

#### 原理

##### 帧

所有帧都是一个固定的 9 字节头部 (payload 之前) 跟一个指定长度的负载 (payload):

共分为十种类型的帧:

HEADERS: 报头帧 (type=0x1)，用来打开一个流或者携带一个首部块片段
DATA: 数据帧 (type=0x0)，装填主体信息，可以用一个或多个 DATA 帧来返回一个请求的响应主体
PRIORITY: 优先级帧 (type=0x2)，指定发送者建议的流优先级，可以在任何流状态下发送 PRIORITY 帧，包括空闲 (idle) 和关闭 (closed) 的流

##### 流

流只是一个逻辑上的概念，代表 HTTP/2 连接中在客户端和服务器之间交换的独立双向帧序列，每个帧的 Stream Identifier 字段指明了它属于哪个流。

流有以下特性:

单个 h2 连接可以包含多个并发的流，两端之间可以交叉发送不同流的帧
流可以由客户端或服务器来单方面地建立和使用，或者共享
流可以由任一方关闭
帧在流上发送的顺序非常重要，最后接收方会把相同 Stream Identifier (同一个流) 的帧重新组装成完整消息报文

